## ЁЯкЯ Windows-ржП Ollama ржЗржирзНрж╕ржЯрж▓ ржЧрж╛ржЗржб тЬЕ

### ЁЯФ╣ Step 1: ржбрж╛ржЙржирж▓рзЛржб ржХрж░рзБржи

ЁЯСЙ ржирж┐ржЪрзЗрж░ рж▓рж┐ржВржХрзЗ ржпрж╛ржи:
ЁЯМР [https://ollama.com/download](https://ollama.com/download)

* ржкрзЗржЬ ржУржкрзЗржи рж╣рж▓рзЗ **тАЬDownload for WindowsтАЭ** ржмрж╛ржЯржирзЗ ржХрзНрж▓рж┐ржХ ржХрж░рзБржиред
* ржПржХржЯрж┐ ржлрж╛ржЗрж▓ ржирж╛ржоржмрзЗ: `OllamaSetup.exe`

---

### ЁЯФ╣ Step 2: ржЗржирж╕рзНржЯрж▓ ржХрж░рзБржи

1. `OllamaSetup.exe` ржлрж╛ржЗрж▓ржЯрж┐рждрзЗ ржбрж╛ржмрж▓ ржХрзНрж▓рж┐ржХ ржХрж░рзБржиред
2. тАЬNextтАЭ, тАЬInstallтАЭ, тАЬFinishтАЭ тАФ ржПржЧрзБрж▓рзЛрждрзЗ ржХрзНрж▓рж┐ржХ ржХрж░рзЗ рж╕рзНржмрж╛ржнрж╛ржмрж┐ржХржнрж╛ржмрзЗ ржЗржирж╕рзНржЯрж▓ рж╢рзЗрж╖ ржХрж░рзБржиред
3. ржЗржирж╕рзНржЯрж▓ рж╢рзЗрж╖ рж╣рж▓рзЗ Ollama ржмрзНржпрж╛ржХржЧрзНрж░рж╛ржЙржирзНржбрзЗ ржЪрж╛рж▓рзБ ржерж╛ржХржмрзЗ (Windows Service рж╣рж┐рж╕рзЗржмрзЗ)ред

---

### ЁЯФ╣ Step 3: ржЯрж╛рж░рзНржорж┐ржирж╛рж▓ ржЦрзБрж▓рзБржи (PowerShell ржмрж╛ CMD)

1. Start ржорзЗржирзБрждрзЗ ржЧрж┐рзЯрзЗ **"Command Prompt"** ржмрж╛ **"PowerShell"** рж▓рж┐ржЦрзЗ ржЦрзБрж▓рзБржиред
2. ржПржмрж╛рж░ ржирж┐ржЪрзЗрж░ ржХржорж╛ржирзНржб рж▓рж┐ржЦрзБржи:

```bash
ollama pull mistral
ollama pull nomic-embed-text
```
### Test Run

```
ollama run mistral
ollama run nomic-embed-text
```
### List 
```
ollama list
```

## ЁЯТ╗ ржзрж╛ржк рзз: ржЖржкржирж╛рж░ ржХржорзНржкрж┐ржЙржЯрж╛рж░рзЗ ржирж┐ржЪрзЗрж░ ржкрзНржпрж╛ржХрзЗржЬржЧрзБрж▓рзЛ ржЗржирж╕рзНржЯрж▓ ржХрж░рзБржи

ржЯрж╛рж░рзНржорж┐ржирж╛рж▓рзЗ (PowerShell/Command Prompt) рж▓рж┐ржЦрзБржи:

```bash
pip install langchain langchain-community langchain-core faiss-cpu tiktoken

pip install -U langchain-ollama
```

ржПржЧрзБрж▓рзЛ ржирж╛ ржерж╛ржХрж▓рзЗ chatbot ржХрж╛ржЬ ржХрж░ржмрзЗ ржирж╛ред
(тЪая╕П ржПржЯрж╛ ржПржХржмрж╛рж░ржЗ ржХрж░рждрзЗ рж╣рзЯ)

---

## ЁЯУБ ржзрж╛ржк рзи: `leave_policy.txt` ржирж╛ржорзЗ ржПржХржЯрж┐ ржлрж╛ржЗрж▓ ржмрж╛ржирж╛ржи

ржПржЗ ржлрж╛ржЗрж▓ржЯрж┐ ржмрж╛ржирж┐рзЯрзЗ ржирж┐ржЪрзЗрж░ ржорждрзЛ ржХржиржЯрзЗржирзНржЯ ржмрж╕рж╛ржи:

```
Company HR Policies 2024

1. Leave Policy:
- ржкрзНрж░рждрж┐ ржХрж░рзНржорзА ржмржЫрж░рзЗ рзирзж ржжрж┐ржи ржкрзЗржЗржб ржЫрзБржЯрж┐ ржкрж╛рзЯред
- рзз ржмржЫрж░рзЗрж░ ржмрзЗрж╢рж┐ ржЪрж╛ржХрж░рж┐ ржХрж░рж▓рзЗ рзм ржорж╛рж╕рзЗрж░ ржорж╛рждрзГрждрзНржмржХрж╛рж▓рзАржи ржЫрзБржЯрж┐ ржкрж╛ржУрзЯрж╛ ржпрж╛рзЯред

2. ржмрзЗрждржи:
- ржмрзЗрждржирзЗрж░ рждржерзНржп ржЧрзЛржкржи ржПржмржВ рж╢рзБржзрзБржорж╛рждрзНрж░ HR_Admin рж░рзЛрж▓ ржжрзЗржЦрждрзЗ ржкрж╛рзЯред

3. Promotion Policy:
- ржкрзНрж░рждрж┐ ржмржЫрж░ ржХрж░рзНржорзАржжрзЗрж░ performance ржЕржирзБржпрж╛рзЯрзА ржкрзНрж░ржорзЛрж╢ржи рж╣рзЯред

4. ржЕржлрж┐рж╕ рж╕ржорзЯрж╕рзВржЪрж┐:
- рж╕ржХрж╛рж▓ рзпржЯрж╛ ржерзЗржХрзЗ ржмрж┐ржХрзЗрж▓ рзмржЯрж╛ (рж░ржмрж┐ржмрж╛рж░ ржерзЗржХрзЗ ржмрзГрж╣рж╕рзНржкрждрж┐ржмрж╛рж░)ред
```

---

## ЁЯза ржзрж╛ржк рзй: Python ржХрзЛржб рж░рж╛ржи ржХрж░рзБржи

ржирж┐ржЪрзЗрж░ ржХрзЛржбржЯрж╛ `chatbot.py` ржирж╛ржорзЗ рж╕рзЗржн ржХрж░рзЗ ржЪрж╛рж▓рж╛ржи:

```python
import csv
from langchain.schema import Document
from langchain.text_splitter import CharacterTextSplitter
from langchain_ollama import OllamaEmbeddings, OllamaLLM
from langchain_community.vectorstores import FAISS
from langchain_community.llms import Ollama
from langchain.chains import RetrievalQA

# Step 1: CSV ржерзЗржХрзЗ ржбрж╛ржЯрж╛ ржкржбрж╝рзЗ ржПржХржЯрж╛ржирж╛ ржЯрзЗржХрзНрж╕ржЯ ржмрж╛ржирж╛ржирзЛ
def read_csv_as_text(file_path):
    with open(file_path, encoding='utf-8') as f:
        reader = csv.DictReader(f)
        text = ""
        for row in reader:
            # ржЙржжрж╛рж╣рж░ржг рж╣рж┐рж╕рзЗржмрзЗ leave_policy.csv ржПрж░ ржЬржирзНржп
            text += f"Employee {row['EmployeeName']} ({row['EmployeeID']}) is allowed {row['AllowedDays']} days {row['LeaveType']} in {row['Year']}, taken {row['TakenDays']} days.\n"
    return text

# CSV ржлрж╛ржЗрж▓рзЗрж░ ржирж╛ржо ржПржЦрж╛ржирзЗ рж╕рзЗржЯ ржХрж░рзЛ
csv_file = "leave_policy.csv"

# Step 2: ржбрж╛ржЯрж╛ рж▓рзЛржб ржУ Document ржП рж░рзВржкрж╛ржирзНрждрж░
data_text = read_csv_as_text(csv_file)
documents = [Document(page_content=data_text)]

# Step 3: ржЯрзЗржХрзНрж╕ржЯ рж╕рзНржкрзНрж▓рж┐ржЯ ржХрж░рж╛ (chunk ржмрж╛ржирж╛ржирзЛ)
text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
texts = text_splitter.split_documents(documents)

# Step 4: ржПржорзНржмрзЗржбрж┐ржВ рждрзИрж░рж┐
embeddings = OllamaEmbeddings(model="nomic-embed-text")
db = FAISS.from_documents(texts, embeddings)

# Step 5: LLM ржУ QA Chain рждрзИрж░рж┐
llm = OllamaLLM(model="mistral")
qa = RetrievalQA.from_chain_type(llm=llm, retriever=db.as_retriever())

# Step 6: ржЗржЙржЬрж╛рж░ ржЗржирзНржЯрж╛рж░ржлрзЗрж╕ (ржЗржиржкрзБржЯ ржЖржЙржЯржкрзБржЯ рж▓рзБржк)
print("\nЁЯдЦ Chatbot ржЪрж╛рж▓рзБ тЬЕ (exit рж▓рж┐ржЦрзЗ ржмрзЗрж░ рж╣рзЛржи)\n")
while True:
    query = input("ЁЯзС ржЖржкржирж┐: ")
    if query.lower() == "exit":
        print("ржмрж┐ржжрж╛рзЯ! ЁЯШК")
        break
    answer = qa.invoke({"query": query})
    print("ЁЯдЦ Bot:", answer["result"], "\n")
```

---

## ЁЯзк ржПржЦржи ржЪрж╛рж▓рж╛ржи:

```bash
python chatbot.py
```

---

## ЁЯЧгя╕П ржЙржжрж╛рж╣рж░ржг ржкрзНрж░рж╢рзНржи ржХрж░рзБржи:

```
ржЖржорж┐ ржХрж┐ maternity leave ржирж┐рждрзЗ ржкрж╛рж░ржмрзЛ?
ржЖржорж╛рж░ ржЫрзБржЯрж┐ ржХрждрзЛ?
office ржХржмрзЗ ржЦрзЛрж▓рж╛ ржерж╛ржХрзЗ?
```


ржжрж╛рж░рзБржг ржкрзНрж░рж╢рзНржи, Mainul! ЁЯШК
ржЖржорж╛рж░ (ржорж╛ржирзЗ ChatGPT-ржПрж░) UI ржпрзЗржЯрж╛ рждрзБржорж┐ ржПржЦржи ржжрзЗржЦржЫрзЛ тАФ ржПржЯрж╛ ржмрж╛ржирж╛ржирзЛ рж╣рзЯрзЗржЫрзЗ **React.js** ржжрж┐рзЯрзЗ, ржЖрж░ backend-ржП ржЖржЫрзЗ **Python-based microservices**, ржкрж╛рж╢рж╛ржкрж╛рж╢рж┐ **OpenAI API**ред
ржПржЯрж╛ ржЦрзБржмржЗ modern, scalable ржУ user-friendlyред

---

## тЬЕ рждрзЛржорж╛рж░ ржЬржирзНржп ржХрзЛржиржЯрж╛ ржнрж╛рж▓рзЛ рж╣ржмрзЗ?

### рждрзБржорж┐ ржпрзЗрж╣рзЗрждрзБ MERN Stack ржПржмржВ DevOps ржжрзБржЯрж┐рждрзЗржЗ ржХрж╛ржЬ ржХрж░рзЛ, рждрж╛ржЗ ржЖржорж┐ suggest ржХрж░ржмрзЛ:

### ЁЯСЙ **Frontend**: React.js + Tailwind CSS

### ЁЯСЙ **Backend**: FastAPI (Python-based)

---

### ЁЯОп ржХрзЗржи ржПржЗ ржХржорзНржмрж┐ржирзЗрж╢ржи?

| Layer      | Technology   | ржХрж╛рж░ржг                                                                             |
| ---------- | ------------ | -------------------------------------------------------------------------------- |
| UI         | React.js     | Reusable components, SPA support, chat-style layout рж╕рж╣ржЬрзЗ ржХрж░рж╛ ржпрж╛рзЯ                 |
| Styling    | Tailwind CSS | Utility-first CSS framework, ржжрзНрж░рзБржд UI ржмрж╛ржирж╛ржирзЛ ржпрж╛рзЯ                                 |
| API Server | FastAPI      | Fast, async-supported, Python-ржП рж╣ржУрзЯрж╛рзЯ рждрзЛржорж╛рж░ LangChain ржУ Ollama рж╕рж╣ржЬрзЗ integrate рж╣рзЯ |
| LLM Engine | Ollama       | Local model ржЪрж▓ржмрзЗ fast, secure ржПржмржВ free                                           |

---

## тЬЕ рждрзЛржорж╛рж░ Project Structure ржХрзЗржоржи рж╣рждрзЗ ржкрж╛рж░рзЗ:

```
ЁЯУж chatbot-app/
тФЬтФАтФА frontend/          # React.js app
тФВ   тФЬтФАтФА App.jsx
тФВ   тФЬтФАтФА ChatUI.jsx
тФВ   тФФтФАтФА ...
тФЬтФАтФА backend/           # FastAPI backend
тФВ   тФЬтФАтФА main.py        # API endpoints
тФВ   тФЬтФАтФА chatbot.py     # LangChain logic
тФВ   тФФтФАтФА ...
```

---

## ЁЯОп ржЖржорж░рж╛ ржХрзА ржмрж╛ржирж╛рждрзЗ ржпрж╛ржЪрзНржЫрж┐?

тЬЕ A simple yet modern **Chat UI** using **React.js + Tailwind CSS**
тЬЕ Chat box, message bubbles, input field, and loading state
тЬЕ Later, weтАЩll connect this UI to your backend (FastAPI + Ollama)

---

## ЁЯУБ Project Structure (Frontend Only)

```
chatbot-frontend/
тФЬтФАтФА public/
тФЬтФАтФА src/
тФВ   тФЬтФАтФА components/
тФВ   тФВ   тФФтФАтФА ChatBox.jsx
тФВ   тФЬтФАтФА App.jsx
тФВ   тФЬтФАтФА index.js
тФЬтФАтФА tailwind.config.js
тФЬтФАтФА package.json
```

---

## тЬЕ Step-by-Step Instructions

### Step 1: Initialize Project

```bash
npm create vite@latest chatbot-ui -- --template react
cd chatbot-ui
npm install
```

### Step 2: Build Chat UI

#### ЁЯзй `src/components/ChatBox.jsx`

```jsx
import { useState } from "react";

export default function ChatUI() {
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState("");
  const [activeTab, setActiveTab] = useState("General");
  const [loading, setLoading] = useState(false);

  const sendMessage = async () => {
    if (!input.trim()) return;
    const userMsg = { role: "user", content: input, tab: activeTab };
    setMessages(prev => [...prev, userMsg]);
    setInput("");
    setLoading(true);

    try {
      const res = await fetch("http://localhost:8000/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ message: input }),
      });
      const data = await res.json();
      setMessages(prev => [
        ...prev,
        { role: "bot", content: data.reply, tab: activeTab },
      ]);
    } catch (err) {
      setMessages(prev => [
        ...prev,
        { role: "bot", content: "ЁЯЪи Server error!", tab: activeTab },
      ]);
    }

    setLoading(false);
  };

  const filteredMessages = messages.filter(msg => msg.tab === activeTab);

  return (
    <div className="app">
      <aside className="sidebar">
        <h2>ChatBot</h2>
        <ul className="chat-list">
          {["General", "HR", "Sales"].map(tab => (
            <li
              key={tab}
              className={tab === activeTab ? "active" : ""}
              onClick={() => setActiveTab(tab)}
            >
              {tab}
            </li>
          ))}
        </ul>
      </aside>

      <main className="chat-main">
        <div className="top-bar">ЁЯФН {activeTab} ржмрж┐ржнрж╛ржЧрзЗ ржЖржЫрзЗржи</div>

        <div className="chat-box">
          {filteredMessages.map((msg, index) => (
            <div key={index} className={`message ${msg.role}`}>
              <span className="message-content">{msg.content}</span>
            </div>
          ))}

          {loading && (
            <div className="message bot typing-indicator">
              <span className="message-content">...</span>
            </div>
          )}
        </div>

        <div className="input-area">
          <input
            value={input}
            onChange={e => setInput(e.target.value)}
            placeholder="ржЖржкржирж╛рж░ ржкрзНрж░рж╢рзНржи рж▓рж┐ржЦрзБржи..."
            onKeyDown={e => e.key === 'Enter' && sendMessage()}
          />
          <button onClick={sendMessage} disabled={loading}>
            {loading ? "..." : "Send"}
          </button>
        </div>
      </main>
    </div>
  );
}

```

#### ЁЯзй `src/App.jsx`

```jsx
import React from "react";
import ChatBox from "./components/ChatBox";

function App() {
  return (
    <div className="bg-gray-50 min-h-screen">
      <ChatBox />
    </div>
  );
}

export default App;
```

---

### тЬЕ Step 4: Run the App

```bash
npm start
```

Now visit `http://localhost:5173` тАФ рждрзБржорж┐ ржжрзЗржЦрждрзЗ ржкрж╛ржмрзЗ ржПржХржЯрж╛ clean, modern chat interface.

---

### ЁЯФЧ Next Step:

Ready hole backend ржмрж╛ржирж╛ржмрзЛ тАФ ржпрж╛ Ollama + LangChain ржПрж░ рж╕рж╛ржерзЗ connect ржХрж░ржмрзЗред

**рждрзБржорж┐ ржХрж┐ ржкрзНрж░рж╕рзНрждрзБржд backend part ржПрж░ ржЬржирзНржп?** ЁЯШОЁЯУб


## ЁЯза Next Step:

рждрзБржорж┐ ржЪрж╛ржЗрж▓рзЗ ржЖржорж┐ ржПржЦржи рждрзЛржорж╛рж░ ржЬржирзНржп FastAPI-based backend рждрзИрж░рж┐ ржХрж░рзЗ ржжрж┐рждрзЗ ржкрж╛рж░рж┐, ржпрзЗржЦрж╛ржирзЗ ржПржЗ React UI ЁЯСЙ Ollama + LangChain-ржПрж░ рж╕рж╛ржерзЗ рж╕ржВржпрзЛржЧ ржХрж░ржмрзЗред

**рждрзБржорж┐ ржХрж┐ backend ржЪрж╛ржУ ржПржЦржи?** тЬЕЁЯза


## ржПржмрж╛рж░ **backend рждрзИрж░рж┐ ржХрж░ржмрзЛ React UIтАСржПрж░ рж╕рж╛ржерзЗ ржХрж╛ржЬ ржХрж░рж╛рж░ ржЬржирзНржпред** ржирж┐ржЪрзЗ ржЖржорж┐ ржУрзЯрж╛ржирж╕рзНржЯржк **FastAPI + Ollama** ржмрзЗржЬржб backend ржХрзЛржб ржжрж┐ржЪрзНржЫрж┐, ржпрж╛ ReactтАСржПрж░ fetch ржХрж▓ ржжрж┐рзЯрзЗ chat endpoint ржерзЗржХрзЗ ржЙрждрзНрждрж░ ржжрж┐ржмрзЗред

---

## ЁЯЫая╕П рж╕рзЗржЯржЖржк ржзрж╛ржкрзЗ ржзрж╛ржкрзЗ

### 1я╕ПтГг Python Dependencies ржЗржирж╕рзНржЯрж▓ ржХрж░рзЛ:

```bash
pip install fastapi uvicorn langchain-community fastapi-cors
pip install ollama
```

### 2я╕ПтГг `main.py` тАУ FastAPI + Ollama Backend

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain_ollama import OllamaLLM

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],  # React runs ржПржЦрж╛ржирзЗ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

llm = OllamaLLM(model="mistral", temperature=0.7)

class ChatRequest(BaseModel):
    message: str


@app.post("/chat")
async def chat_endpoint(req: ChatRequest):
    prompt = req.message
    response = llm.invoke(prompt)
    return {"reply": response}
```

ЁЯФе ржПржЦрж╛ржирзЗ ржЖржорж░рж╛ `Ollama` ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗржЫрж┐ рж▓рзЛржХрж╛рж▓ LLM ржЪрж╛рж▓рж╛ржирзЛрж░ ржЬржирзНржп, ржЖрж░ FastAPI ржжрж┐рзЯрзЗ `/chat` endpoint рждрзИрж░рж┐ ржХрж░рзЗржЫрж┐ред

---

### 3я╕ПтГг Server ржЪрж╛рж▓рж╛ржУ:

```bash
uvicorn main:app --reload --port 8000
```

---

## тЬЕ тЬЕ тЬЕ ржЪрзВрзЬрж╛ржирзНржд тАС Summary

| ржЕржВрж╢         | тЬи ржХрж╛ржЬ                             |
| ----------- | --------------------------------- |
| **FastAPI** | `/chat` endpoint, CORS enabled тЬФ  |
| **Ollama**  | рж▓рзЛржХрж╛рж▓ LLM, `mistral` ржоржбрзЗрж▓ ржмрзНржпржмрж╣рж╛рж░ |
| **React**   | fetch call, ржорзЗрж╕рзЗржЬ UI ржЕржЯрзЛ рж░рзЗржирзНржбрж╛рж░  |

---

## Relode App : uvicorn main:app --reload --port 8000
